{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Rivulet: U. S. NOAA CoastWatch and OceanWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install erddapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Part 0: Connect to API and Establish Custom Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from erddapy import ERDDAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_MIN = 24.0\n",
    "LAT_MAX = 30.0\n",
    "LON_MIN = -90.0\n",
    "LON_MAX = -80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DATE_STR = '2025-09-15' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Part 1: Connect to CoastWatch to Obtain Recent Sea Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Like the issue with AQS versus AirNow, NOAA CoastWatch data includes versions that feature near real-time data and versions that are delayed for quality control purposes.\n",
    "\n",
    "We'll use a version that is quality controlled for scientific research here, but it is possible to access realtime data if you are interested in fetching a dataset that is related to a current event of interest by selecting a different DATASET_ID. Note that those data have not gone through the same rigor of validation processes. \n",
    "\n",
    "NOTE If you need data older than 2015, you should look for the \"Reprocessed\" or \"Science Quality\" dataset on the NOAA ERDDAP site, often labeled as noaacwSlaDaily or similar.\n",
    "\n",
    "Visit https://coastwatch.noaa.gov/cw_html/cwViewer.html\n",
    "For documentation about the API check out https://coastwatch.noaa.gov/erddap/index.html\n",
    "A list of all datasets is here: https://coastwatch.noaa.gov/erddap/info/index.html?page=1&itemsPerPage=2000 (Note not all datasets are publicly accessible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this section accessing recent data, we want to use coastwatch\n",
    "\n",
    "erddap_obj = ERDDAP(\n",
    "    server='https://coastwatch.noaa.gov/erddap',\n",
    "    protocol='griddap',\n",
    "    response='nc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended by Gemini; REVSIT THIS\n",
    "# The dataset IDs are mapped to measures in last column of dataset list above\n",
    "DATASET_ID = 'noaacwBLENDEDsshDaily' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "target_date = datetime.strptime(TARGET_DATE_STR, '%Y-%m-%d')\n",
    "\n",
    "window_start = target_date + timedelta(days=5)\n",
    "window_end = target_date - timedelta(days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fetching data from {DATASET_ID}...\")\n",
    "print(f\"Time: {window_start} to {window_end}\")\n",
    "print(f\"Box: Lat({LAT_MIN}), Lon({LON_MAX})\")\n",
    "    \n",
    "erddap_obj.dataset_id = DATASET_ID\n",
    "    \n",
    "# Set constraints\n",
    "erddap_obj.griddap_initialize()\n",
    "\n",
    "erddap_obj.constraints['time>='] = window_start\n",
    "erddap_obj.constraints['time<='] = window_end\n",
    "erddap_obj.constraints['latitude>='] = LAT_MIN\n",
    "erddap_obj.constraints['latitude<='] = LAT_MAX\n",
    "erddap_obj.constraints['longitude>='] = LON_MIN\n",
    "erddap_obj.constraints['longitude<='] = LON_MAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Select the data to fetch below. \"sla\" is sea level anomaly (the deviation from mean sea surface hieght)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables to download (ssh/sla and coordinates)\n",
    "erddap_obj.variables = ['sla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_sla_data = erddap_obj.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_sla_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_sla_data.to_csv('sealevel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Part 2: Connect to OceanWatch to Obtain Historical Sea Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Now let's fetch some data from 10 years prior to the target date for comparison. For data earlier than 2015, we need to use a different database, AOML, and the appropriate yearly dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "erddap_obj = ERDDAP(\n",
    "    server='https://erddap.aoml.noaa.gov/hdb/erddap', \n",
    "    protocol='griddap',\n",
    "    response='nc'\n",
    ")\n",
    "\n",
    "# Set to the correct database for data 10 years earlier\n",
    "ten_years_ago = target_date.year - 10\n",
    "\n",
    "ten_years_earlier = target_date.replace(year=ten_years_ago)\n",
    "\n",
    "window_start = ten_years_earlier + timedelta(days=5)\n",
    "window_end = ten_years_earlier - timedelta(days=5)\n",
    "\n",
    "DATASET_ID = f'SEA_SURFACE_HEIGHT_{str(ten_years_ago)}_v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "erddap_obj.dataset_id = DATASET_ID\n",
    "\n",
    "erddap_obj.griddap_initialize()\n",
    "\n",
    "erddap_obj.constraints['time>='] = window_start\n",
    "erddap_obj.constraints['time<='] = window_end\n",
    "erddap_obj.constraints['latitude>='] = LAT_MIN\n",
    "erddap_obj.constraints['latitude<='] = LAT_MAX\n",
    "erddap_obj.constraints['longitude>='] = LON_MIN\n",
    "erddap_obj.constraints['longitude<='] = LON_MAX\n",
    "\n",
    "ten_year_data = erddap_obj.to_pandas()\n",
    "ten_year_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "The dataset starts in 1993, so for most recent-ish years, you can get data from 10 and 20 years ago. Below, we repeat the process one more time to fetch data from 20 years prior to the target date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_years_ago = target_date.year - 20\n",
    "erddap_obj.dataset_id = f'SEA_SURFACE_HEIGHT_{str(twenty_years_ago)}_v3'\n",
    "\n",
    "twenty_years_earlier = target_date.replace(year=twenty_years_ago)\n",
    "\n",
    "window_start = twenty_years_earlier + timedelta(days=5)\n",
    "window_end = twenty_years_earlier - timedelta(days=5)\n",
    "\n",
    "erddap_obj.griddap_initialize()\n",
    "\n",
    "erddap_obj.constraints['time>='] = window_start\n",
    "erddap_obj.constraints['time<='] = window_end\n",
    "erddap_obj.constraints['latitude>='] = LAT_MIN\n",
    "erddap_obj.constraints['latitude<='] = LAT_MAX\n",
    "erddap_obj.constraints['longitude>='] = LON_MIN\n",
    "erddap_obj.constraints['longitude<='] = LON_MAX\n",
    "\n",
    "twenty_year_data = erddap_obj.to_pandas()\n",
    "twenty_year_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Let's merge all the datasets, focusing only on sla for now and ignoring all other attributes except latitude and datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_sla_df(df):\n",
    "    cols = df.columns\n",
    "    time_col = next(c for c in cols if 'time' in c.lower())\n",
    "    lat_col = next(c for c in cols if 'lat' in c.lower())\n",
    "    lon_col = next(c for c in cols if 'lon' in c.lower())\n",
    "    sla_col = next(c for c in cols if 'sla' in c.lower())\n",
    "    out = df[[time_col, lat_col, lon_col, sla_col]].copy()\n",
    "    out.columns = ['datetime', 'latitude', 'longitude', 'sla']\n",
    "    out['datetime'] = pd.to_datetime(out['datetime'])\n",
    "    return out\n",
    "\n",
    "merged_sla = pd.concat(\n",
    "    [\n",
    "        _extract_sla_df(latest_sla_data),\n",
    "        _extract_sla_df(ten_year_data),\n",
    "        _extract_sla_df(twenty_year_data),\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "merged_sla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sla.to_csv('sealevelhistoric.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
