{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Rivulet: U. S. EPA Air Quality System\n",
    "_by Michelle H Wilkerson, Lucas Coletti_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook\n",
    "\n",
    "This notebook was developed as part of NSF Grant 2445609 to support accessing and processing AirNow data for middle and high school classroom activities. It's written to be relatively accessible to beginners, but if you have not interacted with computational notebooks or python before you may find navigating this tool difficult. (Check out the Show Your Work project for a gentle introduction to computational notebooks for educators!)\n",
    "\n",
    "Our project is focused on supporting data analysis and mechanistic reasoning in science education. In other words, we want students to learn how data provides information about _how scientific mechanisms work_, and how understanding scientific mechanisms can help them to _explain and interpret patterns in data_. This builds on a long history of research on complex systems and agent-based modeling, and more closely connects that work to current expansions of data analysis across subjects.\n",
    "\n",
    "Here, we are focused on Air Quality as a phenomenon. While most students understand that poor Air Quality can impact health, they may not know that there are many different kinds of air pollution, each caused by different processes and chemicals. These are reflected by different patterns over the course of a day or year\n",
    "\n",
    "This data tool allows users to connect to the Air Quality System API, search for air quality data streams in an area of interest, identify a date range of interest within that area, and then identifies which (if any) of the available data streams recorded observations for _both_ PM2.5 and O3 in that area and time range. These are two key pollutants that impact air quality and that tend to behave very differently over time. These kinds of datasets can serve as a launch to examining what AQ is and what are its underlying mechanistic and compositional complexities.\n",
    "\n",
    "You are welcome to modify and adapt this script. You may find the AQS API documentation [here](https://aqs.epa.gov/aqsweb/documents/data_api.html) and the `pyaqsapi` documentation [here](https://usepa.github.io/pyaqsapi/) helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Part I: Connecting with AQS\n",
    "\n",
    "Before you get started, you will need an AQS API Key. To get one, make a request using the url `https://aqs.epa.gov/data/api/signup?email=myemail@example.com` (replace myemail@example.com with your email). You will recieve a cute sounding API Key via email. Copy it and set EMAIL and API_KEY in the cell block below to your email and key from the service. (You can use the test email and key that are provided, however, the test account has a limited number of uses per day and may not work. Please register for an account if you would like to use the service.) If you need to reset your key, use this same url with the same email address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyaqsapi # python aqs helper\n",
    "\n",
    "EMAIL = \"test@aqs.api\" #replace with your registered email\n",
    "API_KEY = \"test\" # replace with your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Ok, pyaqsapi is super friendly and gives us our data as dataframes. Let's take a look at the monitors available by site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaqsapi as aqs\n",
    "\n",
    "try:\n",
    "    aqs.aqs_credentials(username=EMAIL, key=API_KEY)\n",
    "except Exception as e:\n",
    "    print(f\"Something didn't work: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Now, let's identify a location and time period that we want to explore. AQS can fetch data within a bounding box. Let's not get crazy - start with a relatively small bounding box (try one degree for an urban area) and get bigger if you need. (Tip: If you click on a location in Google Maps, you'll see the lat and long for that point in the URL.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Part II: Identifying a Focal Location and Date\n",
    "\n",
    "This section allows you to specify a location and a date for which you would like to collect data. You'll need to know the approximate longitude and latitude of the region you are interested in. One easy way to do this is by asking Google \"what is the longitude and latitude of [area]?\" You will use the code in this section to use a minimum and maximum latitude and longitude to draw a bounding box around your location of interest. This will filter your future queries to focus only on air quality sensors found within that box. If you don't find any sensors, select a different location or increase the bounding box size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT HERE: Define a bounding box around your\n",
    "# target region. If it is densely populated, we suggest\n",
    "# you start with a bounding box that is only one degree\n",
    "# in area. \n",
    "\n",
    "min_lat = 37 # CHANGE TO YOUR MINIMUM LATITUDE\n",
    "max_lat = 38 # CHANGE TO YOUR MAXIMUM LATITUDE\n",
    "\n",
    "min_long = -122.5 # CHANGE TO YOUR MINIMUM LONGITUDE\n",
    "max_long = -121.5\n",
    "\n",
    "# this is unnecessary but sort of luxurious. let's map the box to\n",
    "# make sure we're capturing what we want.\n",
    "\n",
    "%pip install folium\n",
    "import folium\n",
    "\n",
    "bbox = [[min_lat, min_long], [max_lat, max_long]]\n",
    "\n",
    "# Calculate the center of the box to position the map\n",
    "map_center = [(bbox[0][0] + bbox[1][0]) / 2, (bbox[0][1] + bbox[1][1]) / 2]\n",
    "\n",
    "# Create a Folium map object\n",
    "m = folium.Map(location=map_center, zoom_start=8)\n",
    "\n",
    "# Add a rectangle for the bounding box to the map\n",
    "folium.Rectangle(\n",
    "    bounds=bbox,\n",
    "    color=\"#ff0000\",        # Red border\n",
    "    fill=True,\n",
    "    fill_color=\"#ff7800\",   # Orange fill\n",
    "    fill_opacity=0.2\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT HERE: identify a target date when something interesting\n",
    "# was happening. Below, I define Jun 6 2023, a big wildfire smoke day in NY\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "target_date = \"01-01-2020\"\n",
    "target_datetime = datetime.strptime(target_date, \"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "AQS has settings for different collections of parameters that reflect different \"classes\" of interest. For example, one parameter is SCHOOL AIR TOXICS which highligts 125 pollutants, or HAZARDOUS AIR POLLUTANTS with a total of 407 pollutants (!). Since we're only interested in O3 and PM, let's find a class that has those two and not much else so we're not taxing the system with our queries. AQI POLLUTANTS looks like a good one, it tracks the \"big five\" pollutants that are most commonly discussed along with a few other well known pollutants: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    parameter_list = aqs.aqs_parameters_by_class(\"AQI POLLUTANTS\")\n",
    "except Exception as e:\n",
    "    print(f\"Something didn't work: {e}\")\n",
    "\n",
    "parameter_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "From this list, you can select the specific AQI pollutant parameters that you want to fetch from any of the sequences below. We suggest Ozone (O3) and PM2.5, or Carbon monoxide (CO) and PM2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Part III: AQI and its Constituent Pollutants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "AQI is what's know as a composite index. It looks at the concentrations and risk levels of a core set of six major pollutants (the ones we reviewed as AQI POLLUTANTS above), and reports the highest risk level from those pollutants at a given time. \n",
    "\n",
    "The AQI is one number, and every 50 points represents a new level of hazard. The graphic below shows the general breakdown of AQI warning levels. \n",
    "\n",
    "<img src=\"https://scontent-sjc3-1.xx.fbcdn.net/v/t39.30808-6/500608415_1098175559010383_8931138873982151090_n.jpg?_nc_cat=110&ccb=1-7&_nc_sid=127cfc&_nc_ohc=7RYpSHRmrroQ7kNvwHvDPnd&_nc_oc=AdktzAI6WSrYBPiuFmmAZ1k6gXm91_ewljTyfUuvthEhmAHEKm5ZiAilL2ExyupnwosdWqAKAFC1lZ_vZwzYBu8h&_nc_zt=23&_nc_ht=scontent-sjc3-1.xx&_nc_gid=yQmmRKqszYKw4rWBNjgCEQ&oh=00_AfeX46gOa3fCMWM6oXv50HWl0v6IACWhyblXsMWvLdaW6A&oe=690164F5\" alt=\"alt text\" width=\"400\">\n",
    "\n",
    "In the block below, we define what the EPA calles AQI \"breakpoints\" - these define how different pollutant measures are translated into risk levels that can be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPA Air Quality Index (AQI) Breakpoints\n",
    "# Format: (AQI_Low, AQI_High, Conc_Low, Conc_High)\n",
    "AQI_BREAKPOINTS = {\n",
    "    # PM2.5 (24-hr, in µg/m³)\n",
    "    '88101': [\n",
    "        (0, 50, 0.0, 12.0),\n",
    "        (51, 100, 12.1, 35.4),\n",
    "        (101, 150, 35.5, 55.4),\n",
    "        (151, 200, 55.5, 150.4),\n",
    "        (201, 300, 150.5, 250.4),\n",
    "        (301, 400, 250.5, 350.4),\n",
    "        (401, 500, 350.5, 500.4),\n",
    "    ],\n",
    "    # PM10 (24-hr, in µg/m³)\n",
    "    '81102': [\n",
    "        (0, 50, 0, 54),\n",
    "        (51, 100, 55, 154),\n",
    "        (101, 150, 155, 254),\n",
    "        (151, 200, 255, 354),\n",
    "        (201, 300, 355, 424),\n",
    "        (301, 400, 425, 504),\n",
    "        (401, 500, 505, 604),\n",
    "    ],\n",
    "    # O3 (8-hr, in ppm)\n",
    "    '44201': [\n",
    "        (0, 50, 0.000, 0.054),\n",
    "        (51, 100, 0.055, 0.070),\n",
    "        (101, 150, 0.071, 0.085),\n",
    "        (151, 200, 0.086, 0.105),\n",
    "        (201, 300, 0.106, 0.200),\n",
    "        # Note: AQI > 200 for 8-hr O3 is calculated using 1-hr O3.\n",
    "        # This implementation assumes you will provide the 8-hr value\n",
    "        # and will cap at the 201-300 range.\n",
    "    ],\n",
    "    # O3 (1-hr, in ppm) - Used when 8-hr values are high TODO\n",
    "    'O3_1hr': [\n",
    "        (101, 150, 0.125, 0.164),\n",
    "        (151, 200, 0.165, 0.204),\n",
    "        (201, 300, 0.205, 0.404),\n",
    "        (301, 400, 0.405, 0.504),\n",
    "        (401, 500, 0.505, 0.604),\n",
    "    ],\n",
    "    # CO (8-hr, in ppm)\n",
    "    '42101': [\n",
    "        (0, 50, 0.0, 4.4),\n",
    "        (51, 100, 4.5, 9.4),\n",
    "        (101, 150, 9.5, 12.4),\n",
    "        (151, 200, 12.5, 15.4),\n",
    "        (201, 300, 15.5, 30.4),\n",
    "        (301, 400, 30.5, 40.4),\n",
    "        (401, 500, 40.5, 50.4),\n",
    "    ],\n",
    "    # SO2 (1-hr, in ppb)\n",
    "    '42401': [\n",
    "        (0, 50, 0, 35),\n",
    "        (51, 100, 36, 75),\n",
    "        (101, 150, 76, 185),\n",
    "        (151, 200, 186, 304),\n",
    "        (201, 300, 305, 604),\n",
    "        (301, 400, 605, 804),\n",
    "        (401, 500, 805, 1004),\n",
    "    ],\n",
    "    # NO2 (1-hr, in ppb)\n",
    "    '42602': [\n",
    "        (0, 50, 0, 53),\n",
    "        (51, 100, 54, 100),\n",
    "        (101, 150, 101, 360),\n",
    "        (151, 200, 361, 649),\n",
    "        (201, 300, 650, 1249),\n",
    "        (301, 400, 1250, 1649),\n",
    "        (401, 500, 1650, 2049),\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how the AQI composite measure is constructed.\n",
    "\n",
    "import math\n",
    "\n",
    "# different pollutant measurements are rounded to different places,\n",
    "# this function will do the specified rounding. (TODO: Check if we actually need\n",
    "# this depending on how data are reported by the AQS system)\n",
    "def truncate(n, decimals=0):\n",
    "    \"\"\"\n",
    "    Truncates a float n to a specified number of decimal places,\n",
    "    as required by the EPA AQI calculation.\n",
    "    \n",
    "    Args:\n",
    "        n (float): The number to truncate.\n",
    "        decimals (int): The number of decimal places to keep.\n",
    "        \n",
    "    Returns:\n",
    "        float: The truncated number.\n",
    "    \"\"\"\n",
    "    if not isinstance(n, (int, float)):\n",
    "        return None\n",
    "    if not math.isfinite(n):\n",
    "        return None\n",
    "    \n",
    "    multiplier = 10 ** decimals\n",
    "    return int(n * multiplier) / multiplier\n",
    "\n",
    "# Specification for truncation decimals\n",
    "POLLUTANT_SPECS = {\n",
    "    '88101': {'decimals': 1},\n",
    "    '81102': {'decimals': 0},\n",
    "    '44201': {'decimals': 3},\n",
    "    'O3_1hr': {'decimals': 3},\n",
    "    '42101': {'decimals': 1},\n",
    "    '42401': {'decimals': 0},\n",
    "    '42602': {'decimals': 0},\n",
    "}\n",
    "\n",
    "def calculate_individual_aqi(pollutant_code, concentration):\n",
    "    \"\"\"\n",
    "    Calculates the individual AQI for a single pollutant.\n",
    "    \n",
    "    Args:\n",
    "        pollutant_code (str): The code for the pollutant \n",
    "                              (e.g., 'PM2.5', 'O3_8hr').\n",
    "        concentration (float): The measured concentration.\n",
    "        \n",
    "    Returns:\n",
    "        int: The calculated individual AQI, or None if invalid.\n",
    "    \"\"\"\n",
    "    if pollutant_code not in AQI_BREAKPOINTS or \\\n",
    "       pollutant_code not in POLLUTANT_SPECS:\n",
    "        print(f\"Warning: Unknown pollutant code '{pollutant_code}'.\")\n",
    "        return None\n",
    "        \n",
    "    if concentration is None or concentration < 0 or \\\n",
    "       not math.isfinite(concentration):\n",
    "        return None\n",
    "\n",
    "    # 1. Truncate the concentration based on EPA spec\n",
    "    decimals = POLLUTANT_SPECS[pollutant_code]['decimals']\n",
    "    C_p = truncate(concentration, decimals)\n",
    "    \n",
    "    if C_p is None:\n",
    "        return None\n",
    "\n",
    "    # 2. Find the correct breakpoint category\n",
    "    table = AQI_BREAKPOINTS[pollutant_code]\n",
    "    \n",
    "    for (I_lo, I_hi, C_lo, C_hi) in table:\n",
    "        if C_lo <= C_p <= C_hi:\n",
    "            # 3. Apply the linear interpolation formula\n",
    "            # I_p = ((I_hi - I_lo) / (C_hi - C_lo)) * (C_p - C_lo) + I_lo\n",
    "            \n",
    "            # Avoid division by zero if C_hi == C_lo\n",
    "            if (C_hi - C_lo) == 0:\n",
    "                aqi = I_lo\n",
    "            else:\n",
    "                aqi = ((I_hi - I_lo) / (C_hi - C_lo)) * (C_p - C_lo) + I_lo\n",
    "                \n",
    "            return round(aqi)\n",
    "            \n",
    "    # If concentration is beyond the highest breakpoint,\n",
    "    # use the last category for calculation\n",
    "    (I_lo, I_hi, C_lo, C_hi) = table[-1]\n",
    "    if C_p > C_hi:\n",
    "        if (C_hi - C_lo) == 0:\n",
    "            aqi = I_lo\n",
    "        else:\n",
    "            aqi = ((I_hi - I_lo) / (C_hi - C_lo)) * (C_p - C_lo) + I_lo\n",
    "        return round(aqi)\n",
    "\n",
    "    return None # Should not be reached\n",
    "\n",
    "def calculate_composite_aqi(concentration_data):\n",
    "    \"\"\"\n",
    "    Calculates the overall composite AQI from a dictionary of\n",
    "    available pollutant concentrations.\n",
    "    \n",
    "    The composite AQI is the *maximum* of the individual AQI values.\n",
    "    \n",
    "    Args:\n",
    "        concentration_data (dict): A dictionary where keys are \n",
    "                                   pollutant codes (e.g., 'PM2.5')\n",
    "                                   and values are the concentrations.\n",
    "                                   \n",
    "    Returns:\n",
    "        int: The composite AQI, or None if no valid data was provided.\n",
    "    \"\"\"\n",
    "    individual_aqis = []\n",
    "    \n",
    "    for pollutant_code, concentration in concentration_data.items():\n",
    "        aqi = calculate_individual_aqi(pollutant_code, concentration)\n",
    "        \n",
    "        if aqi is not None:\n",
    "            individual_aqis.append(aqi)\n",
    "            \n",
    "    # The composite AQI is the highest of the available individual AQIs\n",
    "    if not individual_aqis:\n",
    "        return None\n",
    "        \n",
    "    return max(individual_aqis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Ok so the functions we defined above report the AQI given pollutant and concentration. Now what we want to do is find the monitoring station that is recording the highest # of AQI POLLUTANTS. Here, we list the monitoring stations in order of how many of the AQI pollutants are being monitored, and the user can select what they want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdate = target_datetime\n",
    "edate = target_datetime + timedelta(days=1)\n",
    "\n",
    "monitors = aqs.bybox.monitors(\n",
    "    parameter= \"44201,88101,42101,42401,42602,81102\", \n",
    "    bdate=bdate, \n",
    "    edate=edate,\n",
    "    minlat=min_lat,\n",
    "    maxlat=max_lat,\n",
    "    minlon=min_long,\n",
    "    maxlon=max_long,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the monitors so we are showing only the ones that have all requested parameters\n",
    "relevant_monitors = monitors.groupby(\n",
    "    ['state_code','county_code','site_number']).filter( # make groups of each monitor\n",
    "    lambda group: set(group['parameter_code']) == {'44201','88101','42101','42401','42602','81102'} # include only groups with both monitors\n",
    ")\n",
    "\n",
    "\n",
    "relevant_monitors[['state_code','county_code','site_number','address','city_name','county_name','state_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Hopefully, at least one monitor in your designated area appeared that has all pollutants. If not, you may want to remove less commonly measured pollutants from the lambda filter above and see how close you can get.\n",
    "\n",
    "Now, let's identify the monitoring station we want, draw a week of data around our target date, and then calculate the AQI for that period of time as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdate = target_datetime - timedelta(weeks=1)\n",
    "edate = target_datetime + timedelta(weeks=1)\n",
    "\n",
    "aqdata = aqs.bysite.sampledata(parameter=\"44201,88101,42101,42401,42602,81102\",\n",
    "                      bdate=bdate,\n",
    "                      edate=edate,\n",
    "                      stateFIPS=\"06\", # enter the state_code here\n",
    "                      countycode=\"013\", # enter the county_code here\n",
    "                      sitenum=\"0002\") # enter the site_number here\n",
    "\n",
    "aqdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqdata['individual_aqi'] = aqdata.apply(\n",
    "    lambda row: calculate_individual_aqi(row['parameter_code'], row['sample_measurement']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "aqdata['individual_aqi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each datetime in aqdata, compute the composite AQI using calculate_composite_aqi\n",
    "import pandas as pd\n",
    "\n",
    "combined_series = aqdata['date_local'] + ' ' + aqdata['time_local']\n",
    "aqdata['datetime_local'] = pd.to_datetime(combined_series, format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# Pivot so each row is a datetime and columns are pollutant codes with their measurements\n",
    "measurements = aqdata.pivot_table(\n",
    "    index='datetime_local',\n",
    "    columns='parameter_code',\n",
    "    values='sample_measurement',\n",
    "    aggfunc='mean'  # if multiple readings per datetime/pollutant, take the mean\n",
    ")\n",
    "\n",
    "# Helper to build pollutant -> concentration dict and compute composite AQI\n",
    "def _row_to_composite(row):\n",
    "    conc = {str(code): row[code] for code in row.index if pd.notnull(row[code])}\n",
    "    return calculate_composite_aqi(conc)\n",
    "\n",
    "# Compute composite AQI for each datetime\n",
    "measurements['composite_aqi'] = measurements.apply(_row_to_composite, axis=1)\n",
    "\n",
    "# Make a tidy timeseries dataframe\n",
    "aqi_timeseries = measurements[['composite_aqi']].reset_index().sort_values('datetime_local')\n",
    "\n",
    "# Show the result (first rows)\n",
    "aqi_timeseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot\n",
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(aqi_timeseries,x='datetime_local',y='composite_aqi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqdata = aqdata.reset_index()\n",
    "\n",
    "g = sns.FacetGrid(aqdata, \n",
    "                  row=\"parameter_code\", \n",
    "                  aspect=4, # this makes the graphs 4x wider than they are tall\n",
    "                  sharey=False) # this treats the scale for each pollutant separately\n",
    "\n",
    "g.map(sns.lineplot, \"datetime_local\", \"sample_measurement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# Part IV: Identifying O3 and PM monitors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Let's start by getting all the active Ozone and PM2.5 monitors in the bounding box during this target date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdate = target_datetime\n",
    "edate = target_datetime + timedelta(days=1)\n",
    "\n",
    "monitors = aqs.bybox.monitors(\n",
    "    parameter= \"44201,88101\", #44201 identifies ozone\n",
    "    bdate=bdate, \n",
    "    edate=edate,\n",
    "    minlat=min_lat,\n",
    "    maxlat=max_lat,\n",
    "    minlon=min_long,\n",
    "    maxlon=max_long,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter the monitors so we are showing only the ones that have all requested parameters\n",
    "relevant_monitors = monitors.groupby(\n",
    "    ['state_code','county_code','site_number']).filter( # make groups of each monitor\n",
    "    lambda group: set(group['parameter_code']) == {'44201','88101'} # include only groups with both monitors\n",
    ")\n",
    "\n",
    "\n",
    "relevant_monitors[['state_code','county_code','site_number','address','city_name','county_name','state_name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Hopfully, the table above shows some candidate sites from which you can extract information about all of the pollutants you've identified. Let's choose one and take two weeks of sample data (that is the highest resolution of measurements available) around our target date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the site number to focus on above. You'll need the \n",
    "# state_code, county_code, and site_number. I'm going to pick\n",
    "# from the options above site 0011 with state_code = 34 and\n",
    "# county_code = 023.\t\n",
    "\n",
    "# get the 2 week interval around the target\n",
    "bdate = target_datetime - timedelta(weeks=1)\n",
    "edate = target_datetime + timedelta(weeks=1)\n",
    "\n",
    "aqdata = aqs.bysite.sampledata(parameter=\"44201,88101\",\n",
    "                      bdate=bdate,\n",
    "                      edate=edate,\n",
    "                      stateFIPS=\"06\", # enter the state_code here\n",
    "                      countycode=\"001\", # enter the county_code here\n",
    "                      sitenum=\"0011\") # enter the site_number here\n",
    "\n",
    "aqdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Annoyingly, there is a local date and a local time, and a gmt date and a gmt time, but no datetime. Let's add that since otherwise we'll miss useful resoltuion in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "combined_series = aqdata['date_local'] + ' ' + aqdata['time_local']\n",
    "aqdata['datetime_local'] = pd.to_datetime(combined_series, format=\"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Let's take a look at the data we got to see what sorts of patterns are evident for this site at the specified time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "\n",
    "#let's plot\n",
    "import seaborn as sns\n",
    "\n",
    "g = sns.FacetGrid(aqdata, \n",
    "                  row=\"parameter_code\", \n",
    "                  aspect=4, # this makes the graphs 4x wider than they are tall\n",
    "                  sharey=False) # this treats the scale for each pollutant separately\n",
    "\n",
    "g.map(sns.lineplot, \"datetime_local\", \"sample_measurement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "If this is looking good, then you're ready to expore to .csv to use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqdata.to_csv(\"filename.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## Part V: Finding Differences Among Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "In addition to identifying specific events that help you explore differential emission patterns among pollutants, you may want to explore smaller but more robost differences in emissions at near neighbor locations. This may be useful to think about the impacts of particular natural (e.g. a coastal breeze or mountains) or man-made features (e.g. the presence of a freeway or factory) on local air quality patterns over longer periods of time.\n",
    "\n",
    "This section helps you conduct a search within your defined bounding box  for the largest differences in mean concentrations between pollutants. \n",
    "\n",
    "NOTE: Right now I'm doing this for a one-month range around the specified datetime, but maybe talk to Helen or others about what kind of time range is reasonable. Let's identify the month first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the month around the target datetime specified above in Part II\n",
    "bdate = target_datetime - timedelta(days=2)\n",
    "edate = target_datetime + timedelta(days=2)\n",
    "\n",
    "# define the pollutant you want to explore across sites. Below, we model with PM2.5\n",
    "pollutants = \"88101\" ## TODO: Eventually, I think we can bring this out into the setup section since it's used everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Now we are going to report the monitor sites within the bounding box that have the most dramatic differences in mean and range. (Need to think more carefully about what stats to compare here.)\n",
    "\n",
    "So I am going to do a little hack. We don't have monthly aggregated data but we have quarterly. So look at the aggregates from the quarter and use that to decide for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all sites within the bounding box\n",
    "# get the aggregated stats by site of the requested pollutant(s) \n",
    "\n",
    "aqsummary = aqs.bysite.dailysummary(parameter=\"88101\",\n",
    "                      bdate=bdate,\n",
    "                      edate=edate,\n",
    "                      stateFIPS=\"06\", # enter the state_code here\n",
    "                      countycode=\"001\", # enter the county_code here\n",
    "                      sitenum=\"0009\") # enter the site_number here\n",
    "\n",
    "#NOTE - I believe this code is right, but it is hanging for me right now (9/17/25 around 3pm Pacific).\n",
    "#It is also hanging on the corresponding GET request with a different API key so I don't think it's our problem.\n",
    "#What I am trying to do is just see what this looks like for a site I know has the info and then I\n",
    "#will loop through and get all sites in the bounding box to make the comparison.\n",
    "#I'm going to move on to other tasks and come explore later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqsummary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites are uniquely ID'd by county code and site number\n",
    "# turn this into a string so you can group site readings together\n",
    "\n",
    "aqsummary.groupby().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "# Credit\n",
    "\n",
    "https://aqs.epa.gov/aqsweb/documents/about_aqs_data.html\n",
    "\n",
    "Gemini and VSCode Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
