{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Rivulet: U. S. Geological Survey Water Quality APIs\n",
    "_by Michelle H Wilkerson_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook\n",
    "\n",
    "This notebook was developed as part of NSF Grant 2445609 to support accessing and processing public data for middle and high school classroom activities. It's written to be relatively accessible to beginners, but if you have not interacted with computational notebooks or python before you may find navigating this tool difficult. (Check out the Show Your Work project for a gentle introduction to computational notebooks for educators!)\n",
    "\n",
    "Our project is focused on supporting data analysis and mechanistic reasoning in science education. In other words, we want students to learn how data provides information about _how scientific mechanisms work_, and how understanding scientific mechanisms can help them to _explain and interpret patterns in data_. This builds on a long history of research on complex systems and agent-based modeling, and more closely connects that work to current expansions of data analysis across subjects.\n",
    "\n",
    "Here, we are focused on Water Quality as a phenomenon. While most students understand that poor Water Quality can impact health, they may not know what sorts of pollutants impact water quality, and what kinds of events or conditions lead to reductions in water quality.\n",
    "\n",
    "This data tool allows users to connect to the United States Geological Survey (USGS) water data APIs, search for water quality data streams in an area of interest, and then provides a collection of ways to fitler and search the data to ensure you find datasets that have patterns worth exploring. These kinds of datasets can serve as a launch to examining what WQ is and what are its underlying mechanistic and compositional complexities.\n",
    "\n",
    "You are welcome to modify and adapt this script. You may find the USGS' water data APIs documentation [here]() and [here](https://doi-usgs.github.io/dataretrieval-python/) helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Part 0: What is an API? (Click to expand...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Describe APIs, how they work, how common they are in data science, why they are useful for educators and educational researchers who do data science education work to know about. Describe the risks and concerns about APIs and using them to source data that students will interact with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Part I: Connecting with USGS Water Data APIs\n",
    "\n",
    "The USGS has developed a python library (unhelpfully but impressively called `dataretrieval` to help people access and fetch hydrological data from several different water-related data services.\n",
    "\n",
    "You can sign up for an API key [at this site](https://api.waterdata.usgs.gov/signup). Once you recieve it, replace the DEMO_KEY below with your unique API key. Do not share your key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dataretrieval\n",
    "\n",
    "API_KEY = \"DEMO_KEY\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Not sure this is important yet, but the docs say that if you want data after March 2024 you want to specify `legacy=False`. See [here](https://github.com/DOI-USGS/dataretrieval-python#:~:text=%E2%9A%A0%EF%B8%8F,the%20wqp%20module.) and [here](https://doi-usgs.github.io/dataRetrieval/articles/Status.html#:~:text=Discrete%20Data,non%2DUSGS%20data) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataretrieval.nwis as nwis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Part 2: Specifying a Location and Time Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Let's create a bounding box to indicate the region we are interested in. We will then filter our queries to focus only on monitoring sites within the bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT HERE: Define a bounding box around your\n",
    "# target region. If it is densely populated, we suggest\n",
    "# you start with a bounding box that is only one degree\n",
    "# in area. \n",
    "\n",
    "min_lat = 37.5 # CHANGE TO YOUR MINIMUM LATITUDE\n",
    "max_lat = 38 # CHANGE TO YOUR MAXIMUM LATITUDE\n",
    "\n",
    "min_long = -122.5 # CHANGE TO YOUR MINIMUM LONGITUDE\n",
    "max_long = -122\n",
    "\n",
    "# this is unnecessary but sort of luxurious. let's map the box to\n",
    "# make sure we're capturing what we want.\n",
    "\n",
    "import folium\n",
    "\n",
    "bbox = [[min_lat, min_long], [max_lat, max_long]]\n",
    "\n",
    "# Calculate the center of the box to position the map\n",
    "map_center = [(bbox[0][0] + bbox[1][0]) / 2, (bbox[0][1] + bbox[1][1]) / 2]\n",
    "\n",
    "# Create a Folium map object\n",
    "m = folium.Map(location=map_center, zoom_start=8)\n",
    "\n",
    "# Add a rectangle for the bounding box to the map\n",
    "folium.Rectangle(\n",
    "    bounds=bbox,\n",
    "    color=\"#ff0000\",        # Red border\n",
    "    fill=True,\n",
    "    fill_color=\"#ff7800\",   # Orange fill\n",
    "    fill_opacity=0.2\n",
    ").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We're gonna fetch the list of sites within the specified bounding box above. \n",
    "\n",
    "Like the AQS team, the NWIS team is awesome and fetch you some beautiful data. For each request, they pass back a tuple (in this case, a two-ple) of dataframe, metadata. So be sure you catch what's returned with that format. Below, since we are requesting sites, we assign the results of the request to the tuple sites, sites_metadata.\n",
    "\n",
    "Note that at the bottom of the output here, you'll get a URL. That's the corresponding GET request that you can put in to get the same data. Helpful for debugging if something's not working as you would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bBox (list): A contiguous range of decimal latitude and longitude.\n",
    "# Starts with the west longitude, then the south latitude, \n",
    "# then the east longitude, and then the north latitude \n",
    "# with each value separated by a comma. \n",
    "# The product of the range of latitude range and longitude cannot exceed 25 degrees. \n",
    "# TODO: Ok I have no idea how to smartly translate from the idea of min/max \n",
    "# (especially considering different hemispheres) to this idea of east west. \n",
    "# Since these are US Services maybe we can ignore the hemisphere question for now...\n",
    "\n",
    "bbox = str(min_long) + \",\" + str(min_lat) + \",\" + str(max_long) + \",\" + str(max_lat)\n",
    "\n",
    "sites, sites_metadata = nwis.what_sites(bBox=bbox)\n",
    "\n",
    "sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Whoa! Ok that's a lot of sites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Part 3: EColi (?) TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Part 4: Winter Salt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Part 5: Oxygen Dissolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Part 6: Turbidity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "Hodson, T.O., Hariharan, J.A., Black, S., and Horsburgh, J.S., 2023, dataretrieval (Python): a Python package for discovering and retrieving water data available from U.S. federal hydrologic web services: U.S. Geological Survey software release, https://doi.org/10.5066/P94I5TX3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
